% Pieces of state maintained by the pipeline job_coordinator.

-record(stage_info, {start        :: erlang:timestamp(),
                     all     = 0  :: non_neg_integer(),
                     running = [] :: [task_id()],
                     done    = [] :: [input | task_id()]}).
-type stage_info() :: #stage_info{}.
-record(task_info, {spec                :: input | task_spec(),
                    % The worker currently running the task.
                    worker  = none      :: none | pid(),
                    % The outputs generated by the worker.
                    outputs = []        :: [task_output()],
                    % The current waiters from the next stage for this
                    % task's outputs.
                    waiters = []        :: [task_id()],
                    % The tasks from the previous stage that this task
                    % is waiting for.
                    depends = []        :: [task_id()],
                    % Failure statistics.
                    failed_count = 0               :: non_neg_integer(),
                    failed_hosts = gb_sets:empty() :: gb_set()}).
-type task_info() :: #task_info{}.
-record(data_info, {source   :: data_input(),
                    % host() -> data_input() ; where additional copies can be found
                    locations = gb_trees:empty() :: gb_tree(),
                    % data location host() -> non_neg_integer()
                    failures  = gb_trees:empty() :: gb_tree()}).
-type data_info() :: #data_info{}.

% Maximum number of failures to record for intermediate data before
% trying to re-running tasks to re-generate them.
-define(MAX_INPUT_FAILURE, 5).
